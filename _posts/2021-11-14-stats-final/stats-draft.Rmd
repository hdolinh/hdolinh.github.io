---
title: "Environmental Statistics Final"
description: |
  A short description of the post.
author:
  - name: Halina Do-Linh
date: 11-14-2021
output:
  distill::distill_article:
    self_contained: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r loading packages, include=FALSE}

### figure height and size in {r}

library(tidyverse) 
library(here)
library(lintr) # remove maybe
library(janitor)
library(lubridate)
library(kableExtra)
library(xtable)
library(feasts)
library(readr) # remove maybe
library(ggplot2) # remove maybe
library(modelr) # remove maybe
library(knitr) # use this to make kable tables
library(broom)
library(tsibble) # remove maybe
library(zoo)

options(scipen = 999) # disable scientific notation
```

**NO TIME SERIES BECAUSE COULD NOT GET INTO DATE OBJECT**


# Technical Blog Guidelines

**Technical blog post [Due date: 12/2, 5pm]**

This blog post is a write up summarizing in text and with figures and/or tables your question, the data you have collected, your analysis plan, and your results. Your target audience should be other quantitative scientists and practitioners familiar with the basics of statistics and data science, but not necessarily experts in environmental science or the details of the methods studied in this course.

**Please email me your blog post in PDF format and as a live link by 5pm on December 2.**

Some guidelines for the blog post:

-   3-5 pages in length, including figures, tables, captions, and references list
-   1-3 tables or figures, each carefully labeled and captioned so that they are easily interpretable
-   Include scientific references when applicable
-   Include links to the underlying data you use. If your data cannot be shared publicly, note this in a short "data availability" statement at the end of your post.
-   [Recommended, but optional] If you can, include a link to a repository with your replication code. I will not evaluate your code as part of your grade, but this is good practice for reproducibility and transparency and will make your blog post more exciting to the outside world.

# General Guidelines

-   Motivate your question.

    -   Why is this important?

    -   Is there existing evidence on this question?

    -    If so, why is it inconclusive? If not, why not?

-   Describe your data.

    -    Where did you access it? What are its spatial and temporal features?

    -   What are its limitations?

    -   What do you know about the sampling strategy and what biases that may introduce?

    -   If helpful, you can use a histogram, scatterplot, or summary statistics table to describe your data.

-   Clearly describe your analysis plan.

    -   What is your analysis plan?

    -   Why did you choose this analysis, given your data and question?

    -   What are the limitations?

-   Summarize your results visually and in words.

    -   Show us your results in figure(s) and/or table(s) that are carefully labeled and captioned.

    -   Describe in the text (and orally when presenting) what you found, and how these results either do or do not help you answer your question.
    
## Data Setup

### Import Data

I received data from Dr. Scott Jasechko on private wells in California and AK (TBD on what AK is). 

```{r}
wells <- read_csv(here::here("_posts", "2021-11-14-stats-final", "data", "08_CA_AK.csv"))

#"MEDS", "hdolinh.github.io"
```


Here I have made my tidy dataset `wells_tidy`.

- I used `janitor` `clean_names()` to make columns in lowercase and tidy format (i.e. use underscores for spaces).
- I used `select` (from `dpylr` in `tidyverse`) to select my columns of interest. 
- I noticed `well_id` had prefixes "CA" and "AK". I know CA contained observations, but was uncertain about AK. I used `str_detect()` (from `stringr` in `tidyverse`) to created a subset of just AK observations and found that none of the AK well observations are associated with California counties. This confirmed that I should remove well id's that start with AK. I used `filter()` (from `dpylr` in `tidyverse`) and `str_detect()` to do this and removed 36,386 observations. 
- Dr. Jasechko has informed me that values of -1 in the `depth_m` column are NA values, so I removed those using `filter()` (from `dpylr` in `tidyverse`). This removed a significant amount of observations - new total is 642,369.
- I found dates were not in a consistent format so I used `lubridate` `parse_date_time` and the orders mdy, mdy HMS, and mdY to create datetime objects. To simply my overall analysis I created a new column `year_completed` so I could create yearly averages of well depth(m). When I used ascending and descending order to check the `year_completed` column I found there were still issues with dates (i.e. some years were in 2068 or 0101) so I used `filter()` to keep years between 1900 and 2021. 

# found there are some dates with HMY format using table(wells-region$date_completed)

**Because of tidying I have a final dataset of 528,855 well observations between 1900 and 2021.**

```{r, tidy}
wells_tidy <- wells %>% 
  janitor::clean_names() %>% 
  select("well_id", "county", "purpose_5", "date_completed", "depth_m") %>%
  filter(str_detect(well_id, pattern = "CA")) %>% 
  filter(depth_m > -1) %>% 
  mutate(date_completed = lubridate::parse_date_time(date_completed, orders = c("mdy", "mdy HMS", "mdY"))) %>% 
  mutate(year_completed = lubridate::year(date_completed)) %>% 
  filter(year_completed >= 1900 & year_completed <= 2021)
```

I knew I wanted to see if there were any differences in well depth(m) over time between regions in California. So I used `unique()` (base R) to see if all 58 counties were present in the dataset and they are! 

```{r, looking at what CA counties there are}
unique(wells_tidy$county)
```

I knew it would be difficult to compare all 58 counties, so I found on the [California Census website](https://census.ca.gov/regions/) that counties are divided into 10 regions. I created a new column `region_code` and assigned all 58 counties their region code based on the CA.gov website using `case_when()`. If there were any NA values then they would be assigned a region code of 0. This is a new dataset `wells_region`. Since the region codes have a class of numeric, I used `as.factor` to make them a factor/ categorical variable.


```{r, added region codes and made it a factor}
region1 <- c("Butte", "Colusa", "El Dorado", "Glenn", "Lassen", "Modoc", "Nevada", "Placer", "Plumas", "Sacramento", "Shasta", "Sierra", "Siskiyou", "Sutter", "Tehama", "Yolo", "Yuba")
region1_code <- 1

region2 <- c("Del Norte", "Humboldt", "Lake", "Mendocino", "Napa", "Sonoma", "Trinity")
region2_code <- 2

region3 <- c("Alameda", "Contra Costa", "Marin", "San Francisco", "San Mateo", "Santa Clara", "Solano")
region3_code <- 3

region4 <- c("Alpine", "Amador", "Calaveras", "Madera", "Mariposa", "Merced", "Mono", "San Joaquin", "Stanislaus", "Tuolumne")
region4_code <- 4

region5 <- c("Monterey", "San Benito", "San Luis Obispo", "Santa Barbara", "Santa Cruz", "Ventura")
region5_code <- 5

region6 <- c("Fresno", "Inyo", "Kern", "Kings", "Tulare")
region6_code <- 6

region7 <- c("Riverside", "San Bernardino")
region7_code <- 7

region8 <- "Los Angeles"
region8_code <- 8

region9 <- "Orange"
region9_code <- 9

region10<- c("Imperial", "San Diego")
region10_code <- 10

wells_region <- wells_tidy %>% 
  mutate(region_code = case_when(county %in% region1 ~ region1_code,
                                 county %in% region2 ~ region2_code,
                                 county %in% region3 ~ region3_code,
                                 county %in% region4 ~ region4_code,
                                 county %in% region5 ~ region5_code,
                                 county %in% region6 ~ region6_code,
                                 county %in% region7 ~ region7_code,
                                 county %in% region8 ~ region8_code,
                                 county %in% region9 ~ region9_code,
                                 county %in% region10 ~ region10_code,
                                 TRUE ~ 0)) %>% 
  mutate(region_code = as.factor(region_code))
```


**Plot to see distribution of well depth (m). Had to take the log of well depth:**

```{r, distribution of well depth (m)}
log_depth_m <- log(wells_region$depth_m)

depth_hist <- ggplot(data = wells_region, aes(log_depth_m)) +
  geom_histogram() +
  labs(x = "Log of Well Depth (m)",
       y = "Count",
       title = "Distribution of Well Depths (m) in California between 1900 and 2021")
  theme_light()

depth_hist
```

**Plot of regions and number of wells in regions**

```{r, distribution of regions}
# to color cannot use "color" in histogram, need to use "fill"

region_bar <- ggplot(data = wells_region, aes(x = region_code, fill = region_code)) + 
  geom_bar() +
  labs(x = "Region Code",
       y = "Count",
       title = "Distribution of Wells between 1900 and 2021 by Region",
       fill = "Region Code") +  # legend title
  theme_light()

region_bar
```

**Need to count how many wells were completed by year**

**Interpretation: This visually indicates that we are seeing less wells being drilled over time.**

```{r}
wells_counts_year <- wells_region %>% 
  group_by(year_completed) %>% 
  count() %>% 
  rename("total_year" = n)

ggplot(data = wells_counts_year, aes(x = year_completed, y = total_year)) +
  geom_line() +
  labs(x = "Year well was completed",
       y = "Number of wells",
       title = "Total number of wells per year") +
  theme_minimal()
```


**Count how many wells were completed each year and in each region**

**Interpretation: This visually indicates that we are seeing less wells being drilled over time in most if not all regions as well. It also looks like there could be some seasonality...but I was not able to plot this year I could not get my `year_completed` values to be of class `date`.**


```{r}
wells_counts_year_region <- wells_region %>% 
  group_by(region_code, year_completed) %>% 
  count() %>% 
  rename(count = n)

ggplot(data = wells_counts_year_region, aes(x = year_completed, y = count, color = region_code)) +
  geom_line() +
  labs(x = "Year well was completed",
       y = "Number of wells",
       title = "Total number of wells per year by region",
       colour = "Region Code") +
  theme_minimal()
```

```{r}
wells_depth_year <- wells_region %>% 
  select(well_id, year_completed, depth_m) %>% 
  group_by(year_completed) %>% 
  summarize(mean_depth_m_year = mean(depth_m))

ggplot(data = wells_depth_year, aes(x = year_completed, y = mean_depth_m_year)) +
  geom_line() +
  labs(x = "Year well was completed",
       y = "Yearly average well depth (m)",
       title = "Yearly Average Well Depth (m) from 1990 to 2021") +
  theme_minimal()
```


**MULTIPLE LINEAR REGRESSION ANALYSIS**

**Create North/South Region so that you have a categorical variable with only two levels as opposed to 10**

- Plot date (year only), mean of well depth(m), and color by north/south region
- Need to test if this is significant! 

```{r}
norcal <- c(1, 2, 3, 4, 5)
norcal_code <- "north"

socal <- c(6, 7, 8, 9, 10)
socal_code <- "south"

region_north_south <- wells_region %>% 
  mutate(north_south = case_when(region_code %in% norcal ~ norcal_code,
                                 region_code %in% socal ~ socal_code,
                                 TRUE ~ "NA")) %>%
  mutate(north_south = as.factor(north_south)) %>% # make north_south a factor variable
  group_by(year_completed, north_south) %>% 
  mutate(mean_depth_m = mean(depth_m)) # yearly averages by region

mod <- lm(mean_depth_m ~ year_completed + north_south, data = region_north_south)

ggplot(data = region_north_south, aes(x = year_completed, y = mean_depth_m,  color = north_south)) +
  geom_point() +
  geom_line(data = augment(mod), aes(y = .fitted, color = north_south)) +
  labs(x = "Year well was completed",
       y = "Yearly average well depth (m)") +
  scale_colour_discrete("North South Region")
  
```

**Results of model**

```{r}
mod_summary <- lm(mean_depth_m ~ year_completed + north_south, data = region_north_south) %>% summary() 

mod_table <- mod_summary %>% xtable() %>% kbl() %>% kable_material("striped")
mod_table
```


```{r}

mod_interaction <- lm(mean_depth_m ~ year_completed + north_south + year_completed:north_south, data = region_north_south) 
summary(mod_interaction)

```


```{r}
ggplot(region_north_south, aes(y = mean_depth_m, x = year_completed, color = north_south)) + 
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE)
```


```{r}
#mod_interaction <- lm(mean_depth_m ~ year_completed + north_south + year_completed:north_south, data = region_north_south) 

region_north_south %>% 
  ggplot(aes(x = year_completed, y = mean_depth_m, color = north_south)) +
  geom_point() +
  geom_line(data = augment(mod_interaction), aes(y = .fitted, color = north_south)) 
```


```{r}
# no interaction
mod <- lm(mean_depth_m ~ year_completed + north_south, data = region_north_south)
AdjR2 <- summary(mod)$adj.r.squared
print(AdjR2)

# with the interaction
mod_interaction <- lm(mean_depth_m ~ year_completed + north_south + year_completed:north_south, data = region_north_south) 
AdjR2_int <- summary(mod_interaction)$adj.r.squared
print(AdjR2_int)
```
**Interpretation: Since the adjusted $R^2$ value increased slightly, we conclude that the interaction model.....improves the model fit a little (but not meaningfully?). This indicates that the north_south region variable are adding value to the model. **


**TIME SERIES ANALYSIS**

```{r}
# created dataset to use as a timeseries object 
monthly_depth <- region_north_south %>% 
  select(well_id, date_completed, depth_m, region_code, north_south, year_completed) %>% 
  mutate(month_completed = lubridate::month(date_completed)) %>% 
  mutate(month_year_completed = as.yearmon(paste0(year_completed, month_completed), "%Y %m")) %>% 
  mutate(month_year_completed = yearmonth(month_year_completed)) %>% 
  group_by(month_year_completed, north_south) %>% 
  mutate(month_mean_depth_m = mean(depth_m)) %>% # monthly averages
  ungroup()
  
```


```{r}
# classical decomposition analysis 
wells_depth_yearmon <- monthly_depth %>% 
  select(well_id, month_year_completed, depth_m) %>% 
  group_by(month_year_completed) %>% 
  summarize(mean_depth_m_year = mean(depth_m))

wells_tbsl_2 <- as_tsibble(wells_depth_yearmon)

wells_decomp_2 <- wells_tbsl_2 %>% 
  model(classical_decomposition(mean_depth_m_year, type = "additive")) %>%
  components() %>% 
  autoplot()

wells_decomp_2
```






```{r, deleted}
# wells_time_only_year <- wells_region %>% 
#   mutate(date_completed = na.omit(date_completed)
#   mutate(date_completed = format(date_completed, format = "%m/%d/%Y")) %>% 
#   group_by(date_completed) %>% 
#   count() %>% 
#   na.omit
#   mutate(date_completed = lubridate::mdy(date_completed))
# 
# wells_time_only_year <- wells_region %>% 
#   group_by(date_completed) %>% 
#   count()
# 
# wells_time_na <- wells_region %>% 
#   drop_na(date_completed) %>% 
#   mutate(date_completed = lubridate::parse_date_time(date_completed, c("mdy", "mdy HMS", "mdY")))
# 
# # wells_valid_dates <- wells_valid_dates %>% 
# #   group_by(date_completed) %>% 
# #   count()

#  mutate(date_completed = !is.na(strptime(date_completed, format = c("%m/%d/%y", "%m/%d/%Y", "%m/%d/%y HMS")))) this returns a column of TRUE and FALSE values

# well_count_year <- wells_region[!is.na(strptime(wells_region$date_completed, format = c("%m/%d/%y", "%m/%d/%Y", "%m/%d/%y HMS"))),] 
# 
# well_count_year <- well_count_year %>% 
#   mutate(date_completed = lubridate::parse_date_time(date_completed, orders = c("mdy", "mdy HMS", "mdY"))) %>% 
#   mutate(year_completed = lubridate::year(date_completed)) %>% 
#   filter(year_completed >= 1900 & year_completed <= 2021) %>% 
#   group_by(year_completed) %>% 
#   count()

# wells_subset <- monthly_depth %>% 
#   select(well_id, month_year_completed, month_mean_depth_m)
# 
# wells_tbsl <- as_tsibble(wells_subset, key = well_id, index = month_year_completed)
# 
# wells_decomp <-wells_tbsl %>% 
#   model(classical_decomposition(month_mean_depth_m, type = "additive")) %>%
#   components() %>% 
#   autoplot()

# wells_north <- monthly_depth %>% 
#   filter(north_south == "north")
# 
# wells_subset_north <- wells_north %>% 
#   select(well_id, month_year_completed, month_mean_depth_m)
# 
# wells_tbsl_north <- as_tsibble(wells_subset_north, key = well_id, index = month_year_completed)
# 
# wells_decomp_north <- wells_tbsl_north %>% 
#   model(classical_decomposition(month_mean_depth_m, type = "additive")) %>%
#   components() %>% 
#   autoplot()
```


```{r, histogram of wells by region, fig.height=3, fig.width=5}
wells_counts_year_region <- wells_region %>%
  group_by(region_code, year_completed) %>%
  count() %>%
  rename(count = n)

tot_wells_region <- ggplot(data = wells_counts_year_region, aes(x = year_completed, y = count, color = region_code)) +
  geom_line() +
  labs(x = "Year well was completed",
       y = "Number of wells",
       title = "Total number of wells per year by region",
       colour = "Region Code") +
  theme_light() +
  theme(
    panel.grid = element_blank(),
    legend.position = c(0.93, 0.59),
    legend.title = element_text(size = 7),
    legend.text = element_text(size = 7))
tot_wells_region
```


```{r, combined graph attempt}
# #df1
# wells_counts_year <- wells_region %>% 
#   group_by(year_completed) %>% 
#   count() %>% 
#   rename("total_year" = n)
# #df2
# wells_depth_year <- wells_region %>% 
#   select(well_id, year_completed, depth_m) %>% 
#   group_by(year_completed) %>% 
#   summarize(mean_depth_m_year = mean(depth_m))
# 
# mean_depth_m_year <- wells_depth_year$mean_depth_m_year
# 
# #combined ggplot
# tot_wells_yr <- ggplot() +
#   geom_line(data = wells_counts_year, aes(x = year_completed, y = total_year)) +
#   geom_line(data = wells_depth_year, aes(x = year_completed, y = mean_depth_m_year)) +
#   theme_light() +
#   theme(panel.grid = element_blank()) +
#   scale_y_continuous(
#     name = "First Axis",
#     sec.axis = sec_axis(trans = ~.*1, name = "Second Axis")
#   )
# 
# tot_wells_yr
# 
# 
# 
# ggplot() +
#   geom_line() +
#   labs(x = "Year well was completed",
#        y = "Yearly average well depth (m)",
#        title = "Yearly Average Well Depth (m) from 1990 to 2021") +
#   theme_minimal()
```


```{r}
# mod_summary <- lm(mean_depth_m ~ year_completed + north_south, data = region_north_south) %>% 
#   summary() %>% 
#   xtable() %>% 
#   kable()
# 
# mod_summary
```


```{r}
# mod_interaction <- lm(mean_depth_m ~ year_completed + north_south + year_completed:north_south, data = region_north_south) %>% 
# summary() %>% 
#   xtable() %>% 
#   kable()
# 
# mod_interaction
```


```{r}
# wells_counts_year_region <- wells_region %>% 
#   group_by(region_code, year_completed) %>% 
#   count() %>% 
#   rename(count = n)
# 
# wells_counts_year_region_plot <- ggplot(data = wells_counts_year_region, aes(x = year_completed, y = count, color = region_code)) +
#   geom_line() +
#   labs(x = "Year well was completed",
#        y = "Number of wells",
#        title = "Total number of wells per year by region",
#        colour = "Region Code") +
#   guides(color = guide_legend(nrow = 1)) +
#   theme_light() +
#   theme(
#     panel.grid = element_blank(),
#     legend.position = "bottom"
#   )
```


-   What might you do next?

    -   One short analysis cannot fully answer an interesting scientific question.

    -   If you had time to collect more data or conduct more analysis, what would help you answer this question better?

Distill is a publication format for scientific and technical writing, native to the web.

Learn more about using Distill at <https://rstudio.github.io/distill>.
